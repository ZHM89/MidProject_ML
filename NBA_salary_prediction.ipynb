{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data analysis and plotting libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300 # set the resolution of output plots to 600 dpi\n",
    "\n",
    "# Standard machine learning libraries and modules\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBA Players Performance and Salaries\n",
    "Source: https://www.kaggle.com/datasets/thedevastator/exploring-nba-player-performance-and-salaries-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset guide\n",
    "\n",
    "`Checked?` controls if a column has been converted to its correct data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File: salaries_1985to2018.csv\n",
    "\n",
    "| Column    | Description | Checked?\n",
    "| -------- | ------- | -------\n",
    "| league  | The league the player is in. (String) | Yes \n",
    "| salary  | The salary of the player. (Integer)    | Yes \n",
    "| season  | The season the player is playing in. (String)  | Yes \n",
    "| season_end | The end date of the season. (Date) | Yes \n",
    "| season_start | The start date of the season. (Date) | Yes  \n",
    "| team         | The team the player is playing for. (String) | Yes \n",
    "\n",
    "File: players.csv\n",
    "\n",
    "| Column     | Description | Checked?\n",
    "| --------   | ------- | ------- \n",
    "| birthDate  | Date of birth of the player. (Date) | Yes\n",
    "| birthPlace | Place of birth of the player. (String) | Yes\n",
    "| career_AST | Career assists of the player. (Integer) | Yes\n",
    "| career_FG% |Career field goal percentage of the player. (Float) | Yes\n",
    "| career_FG3%|Career three-point field goal percentage of the player. (Float) | Yes\n",
    "| career_FT% | Career free throw percentage of the player. (Float) | Yes\n",
    "|career_G\t |Career games played by the player. (Integer) | Yes\n",
    "|career_PER\t |Career player efficiency rating of the player. (Float) | Yes\n",
    "|career_PTS\t |Career points scored by the player. (Integer)| Yes\n",
    "|career_TRB\t |Career total rebounds of the player. (Integer)| ?\n",
    "|career_WS\t |Career win shares of the player. (Float)| Yes\n",
    "|career_eFG% |Career effective field goal percentage of the player. (Float)| ?\n",
    "|college\t |College attended by the player. (String)| Yes\n",
    "|draft_pick\t |Draft pick of the player. (Integer)| Yes\n",
    "|draft_round |Round of the draft the player was selected in. (Integer)| Yes\n",
    "|draft_team\t |Team that drafted the player. (String)| Yes\n",
    "|draft_year\t |Year the player was drafted. (Integer)| Yes\n",
    "|height\t     |Height of the player. (Float) | Yes\n",
    "|highSchool\t |High school attended by the player. (String) | Yes\n",
    "|name\t     |Name of the player. (String) | Yes\n",
    "|position\t |Position of the player. (String) | Yes\n",
    "|shoots\t     |Shooting hand preference of the player. (String) | Yes\n",
    "|weight\t     |Weight of the player. (Integer) | Yes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.read_csv(\"salaries_1985to2018.csv\")\n",
    "players = pd.read_csv(\"players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps is to merge the two datasets to get a unified one. <br>\n",
    "Let's explore the columns and find a unique column name that we can merge on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets `salaries` and `players` have their own index. Yet, we don't need more than one index for the merged dataset. So we drop the `index` column from one of the DataFrames (e.g., from `salaries`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that, `player_id` in `salaries` and `_id` in `players` are common. Thus, we merge on id values using inner join to keep those players for whom salary details are availale. We also keep in mind to add `left_on` and `right_on` as the key columns have different names. Name the merged DataFrame `nba_salary_stats`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats = salaries.merge(players, how='inner', left_on='player_id', right_on='_id')\n",
    "nba_salary_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete one of the redundant id columns, for instance `_id` from `nba_salary_stats`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.drop(columns=['_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we work with `nba_salary_stats`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows and columns in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for NaN values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats[\"career_FG3%\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check number of rows after removing NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 3370 rows with NaNs are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicated rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = nba_salary_stats.duplicated().sum()\n",
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column transformation and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice several columns of object type which need to be converted to numeric ones. I tried the standard type casting method `.astype()` but it didn't work out, since these columns contain special characters. Instead, I use custom lambda functions to strip off the special characters and only keep the numeric part. The columns `weight` and `height` are a bit more complicated because they contain special characters, and top of that, each needs to be converted to SI units (kg, cm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `weight`, `height` and all columns that contain special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'weight' from lb format to kg \n",
    "nba_salary_stats['weight'] = nba_salary_stats['weight'].apply(\n",
    "    lambda x: float(str(x).replace('lb', '')) * 0.453592 \n",
    ")\n",
    "\n",
    "# Convert 'height' from feet-inches format to cm\n",
    "nba_salary_stats[\"height\"] = nba_salary_stats[\"height\"].apply(\n",
    "    lambda x: float(x.split(\"-\")[0]) * 30.48 + float(x.split(\"-\")[1]) * 2.54 if \n",
    "    isinstance(x, str) and \"-\" in x else np.nan  # Handle NaN or unexpected formats\n",
    ")\n",
    "\n",
    "# Custom function to remove special characters from other columns and set them into numeric\n",
    "extract_numeric = lambda series: series.astype(str).str.extract(r'([-+]?\\d*\\.?\\d+)', expand=False).astype(float)\n",
    "\n",
    "cols_to_convert = [\"career_FG%\", \"career_FG3%\", \"career_eFG%\", \"career_FT%\", \n",
    "                   \"career_PER\", \"draft_year\", \"career_WS\", \"draft_pick\"]\n",
    "\n",
    "nba_salary_stats[cols_to_convert] = nba_salary_stats[cols_to_convert].apply(extract_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `birthDate` to datetime object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert `birthDate` to datetime object:\n",
    "nba_salary_stats['birthDate'] = pd.to_datetime(\n",
    "    nba_salary_stats['birthDate'], \n",
    "    format='%B %d, %Y'  # matching \"MonthName Day, Year\" format\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `birthPlace` into `birth_city` and `nationality` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'birthPlace' into 'birth_city' and 'nationality'\n",
    "nba_salary_stats[['birth_city', 'nationality']] = nba_salary_stats['birthPlace'].str.split(', ', expand=True)\n",
    "# Display a few rows to confirm changes\n",
    "nba_salary_stats[[\"birthPlace\", \"birth_city\", \"nationality\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a `draft_age` column which is the age that a player is drafted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure birthDate is a datetime object\n",
    "nba_salary_stats[\"birthDate\"] = pd.to_datetime(nba_salary_stats[\"birthDate\"], errors=\"coerce\")\n",
    "\n",
    "# Convert draft_year to integer\n",
    "nba_salary_stats[\"draft_year\"] = nba_salary_stats[\"draft_year\"].fillna(0).astype(int)\n",
    "\n",
    "# Compute draft age\n",
    "nba_salary_stats[\"draft_age\"] = nba_salary_stats[\"draft_year\"] - nba_salary_stats[\"birthDate\"].dt.year\n",
    "\n",
    "# Replace negative values in the draft_age column with the median of positive values\n",
    "# Calculate median of positive draft ages\n",
    "positive_median = nba_salary_stats.loc[nba_salary_stats[\"draft_age\"] > 0, \"draft_age\"].median()\n",
    "\n",
    "# Replace negative values with the median of positive ages\n",
    "nba_salary_stats[\"draft_age\"] = nba_salary_stats[\"draft_age\"].apply(\n",
    "    lambda x: positive_median if x < 0 else x\n",
    ")\n",
    "\n",
    "# Display a few rows to confirm changes\n",
    "nba_salary_stats[[\"birthDate\", \"draft_year\", \"draft_age\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove nan values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.dropna(inplace=True)\n",
    "nba_salary_stats.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics of numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sample of 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique players:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats['player_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of players by state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of players per state/country of birth and select the top 10\n",
    "top_nationalities = nba_salary_stats['nationality'].value_counts().nlargest(10)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_nationalities.index, y=top_nationalities.values)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for readability\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Players')\n",
    "plt.title('Number of players by state')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salary Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure with improved proportions\n",
    "plt.figure(figsize=(12, 6), facecolor='white')  # Wider aspect ratio\n",
    "\n",
    "# Create histogram with refined styling\n",
    "ax = sns.histplot(\n",
    "    nba_salary_stats['salary'],\n",
    "    bins=50,\n",
    "    kde=True,\n",
    "    color='#5F9EA0',  # More sophisticated blue\n",
    "    edgecolor='white',  # Clean bar edges\n",
    "    linewidth=0.8,  # Subtle border\n",
    "    alpha=0.85  # Slight transparency\n",
    ")\n",
    "\n",
    "# KDE line styling\n",
    "for line in ax.lines:  # Access the KDE line\n",
    "    line.set_color('#d62728')  # Contrasting red\n",
    "    line.set_linewidth(2)  # Thicker line\n",
    "\n",
    "# Customize labels with improved typography\n",
    "plt.xlabel('Salary ($)', fontsize=12, labelpad=10, fontweight='normal')\n",
    "plt.ylabel('Count of Players', fontsize=12, labelpad=10, fontweight='normal')\n",
    "plt.title('NBA Salary Distribution', \n",
    "          fontsize=14, pad=20, fontweight='bold')\n",
    "\n",
    "# Improve tick marks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Add light grid for better readability\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Remove top and right spines for cleaner look\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draft pick distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure with improved proportions\n",
    "plt.figure(figsize=(12, 6), facecolor='white')  # Wider aspect ratio\n",
    "\n",
    "# Create histogram with refined styling\n",
    "ax = sns.histplot(\n",
    "    nba_salary_stats['draft_pick'],\n",
    "    bins=50,\n",
    "    kde=True,\n",
    "    color='#5F9EA0',  # More sophisticated blue\n",
    "    edgecolor='white',  # Clean bar edges\n",
    "    linewidth=0.8,  # Subtle border\n",
    "    alpha=0.85  # Slight transparency\n",
    ")\n",
    "\n",
    "# KDE line styling\n",
    "for line in ax.lines:  # Access the KDE line\n",
    "    line.set_color('#d62728')  # Contrasting red\n",
    "    line.set_linewidth(2)  # Thicker line\n",
    "\n",
    "# Customize labels with improved typography\n",
    "plt.xlabel('Draft Pick Number', fontsize=12, labelpad=10, fontweight='normal')\n",
    "plt.ylabel('Count of Players', fontsize=12, labelpad=10, fontweight='normal')\n",
    "plt.title('NBA Draft Pick Distribution', \n",
    "          fontsize=14, pad=20, fontweight='bold')\n",
    "\n",
    "# Improve tick marks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Add light grid for better readability\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Remove top and right spines for cleaner look\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between height and three-point field goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6), facecolor='#f8f9fa')\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = sns.scatterplot(\n",
    "    x='height',\n",
    "    y='career_FG3%',\n",
    "    data=nba_salary_stats,\n",
    "    color='#2a9d8f',  # Attractive teal color\n",
    "    alpha=0.7,\n",
    "    s=80,  # Slightly larger points\n",
    "    edgecolor='white',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "# Add regression line\n",
    "sns.regplot(\n",
    "    x='height',\n",
    "    y='career_FG3%',\n",
    "    data=nba_salary_stats,\n",
    "    scatter=False,\n",
    "    color='#e76f51',  # Complementary coral color\n",
    "    line_kws={'linewidth': 2.5}\n",
    ")\n",
    "\n",
    "# Calculate and display correlation\n",
    "correlation = nba_salary_stats['height'].corr(nba_salary_stats['career_FG3%'])\n",
    "plt.text(0.05, 0.95, f'Correlation: {correlation:.2f}', \n",
    "         transform=plt.gca().transAxes,\n",
    "         fontsize=12,\n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='lightgray'))\n",
    "\n",
    "# Labels and title\n",
    "plt.title('Height vs. 3-Point Shooting Accuracy', \n",
    "          fontsize=14, pad=15, fontweight='bold')\n",
    "plt.xlabel('Height (cm)', fontsize=12)\n",
    "plt.ylabel('3-Point FG%', fontsize=12)\n",
    "\n",
    "# Adjust ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Clean up borders\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is salary correlated with three-point field goal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6), facecolor='#f8f9fa')\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = sns.scatterplot(\n",
    "    y='career_FG3%',\n",
    "    x='salary',\n",
    "    data=nba_salary_stats,\n",
    "    color='#2a9d8f',  # Attractive teal color\n",
    "    alpha=0.7,\n",
    "    s=80,  # Slightly larger points\n",
    "    edgecolor='white',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "# Add regression line\n",
    "sns.regplot(\n",
    "    y='career_FG3%',\n",
    "    x='salary',\n",
    "    data=nba_salary_stats,\n",
    "    scatter=False,\n",
    "    color='#e76f51',  # Complementary coral color\n",
    "    line_kws={'linewidth': 2.5}\n",
    ")\n",
    "\n",
    "# Calculate and display correlation\n",
    "correlation = nba_salary_stats['salary'].corr(nba_salary_stats['career_FG3%'])\n",
    "plt.text(0.05, 0.95, f'Correlation: {correlation:.2f}', \n",
    "         transform=plt.gca().transAxes,\n",
    "         fontsize=12,\n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='lightgray'))\n",
    "\n",
    "# Labels and title\n",
    "plt.title('Salary vs. 3-Point Shooting Accuracy', \n",
    "          fontsize=14, pad=15, fontweight='bold')\n",
    "plt.xlabel('Salary ($)', fontsize=12)\n",
    "plt.ylabel('3-Point FG%', fontsize=12)\n",
    "\n",
    "# Adjust ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Clean up borders\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar chart of age at which the player was drafted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and clean draft_age\n",
    "positive_median = nba_salary_stats.loc[nba_salary_stats[\"draft_age\"] > 0, \"draft_age\"].median()\n",
    "nba_salary_stats[\"draft_age_clean\"] = np.where(nba_salary_stats[\"draft_age\"] < 0, \n",
    "                                             positive_median, \n",
    "                                             nba_salary_stats[\"draft_age\"])\n",
    "\n",
    "# Round ages to integers for clean bar labels\n",
    "nba_salary_stats[\"draft_age_int\"] = nba_salary_stats[\"draft_age_clean\"].round().astype(int)\n",
    "\n",
    "# Create countplot (bar chart)\n",
    "plt.figure(figsize=(14, 6))\n",
    "ax = sns.countplot(data=nba_salary_stats,\n",
    "                 x=\"draft_age_int\",\n",
    "                 color=\"#2a9d8f\",\n",
    "                 edgecolor=\"white\",\n",
    "                 linewidth=0.7)\n",
    "\n",
    "# Add median line\n",
    "plt.axvline(x=positive_median - nba_salary_stats[\"draft_age_int\"].min(), \n",
    "            color='red', \n",
    "            linestyle='--',\n",
    "            linewidth=1.5,\n",
    "            label=f'Median: {positive_median:.1f}')\n",
    "\n",
    "# Customize\n",
    "plt.title(\"NBA Players by Draft Age\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"Age at Draft (Years)\", fontsize=12)\n",
    "plt.ylabel(\"Number of Players\", fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add value labels on bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.0f}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='center', \n",
    "                xytext=(0, 5), \n",
    "                textcoords='offset points',\n",
    "                fontsize=9)\n",
    "\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats[\"position\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the given positions\n",
    "selected_positions = [\n",
    "    \"Center\",\n",
    "    \"Point Guard\",\n",
    "    \"Power Forward and Center\",\n",
    "    \"Shooting Guard\",\n",
    "    \"Small Forward\",\n",
    "    \"Power Forward\",\n",
    "    \"Center and Power Forward\",\n",
    "    \"Small Forward and Shooting Guard\",\n",
    "    \"Point Guard and Shooting Guard\",\n",
    "    \"Shooting Guard and Point Guard\",\n",
    "    \"Shooting Guard and Small Forward\",\n",
    "    \"Power Forward and Small Forward\",\n",
    "    \"Small Forward and Power Forward\"\n",
    "]\n",
    "\n",
    "# Filter dataset for selected positions\n",
    "filtered_data = nba_salary_stats[nba_salary_stats[\"position\"].isin(selected_positions)]\n",
    "\n",
    "# Compute median career points for each position and sort in descending order\n",
    "sorted_positions = (\n",
    "    filtered_data.groupby(\"position\")[\"career_PTS\"]\n",
    "    .median()\n",
    "    .sort_values(ascending=False)\n",
    "    .index\n",
    ")\n",
    "\n",
    "# Set figure size and style\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a sorted boxplot\n",
    "ax = sns.boxplot(\n",
    "    x=\"position\",\n",
    "    y=\"career_PTS\",\n",
    "    data=filtered_data,\n",
    "    order=sorted_positions,  # Sort positions based on median career points\n",
    "    palette=\"coolwarm\"\n",
    ")\n",
    "\n",
    "# Adjust y-axis limits dynamically based on data\n",
    "plt.ylim(filtered_data[\"career_PTS\"].min() * 0.9, filtered_data[\"career_PTS\"].max() * 1.1)\n",
    "\n",
    "# Customize labels and title\n",
    "plt.xlabel(\"Position\", fontsize=12)\n",
    "plt.ylabel(\"Career Points\", fontsize=12)\n",
    "plt.title(\"Career Points Distribution for Most Frequent (> 100) Positions (Sorted by Median)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Rotate x-axis labels to prevent overlap\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salary vs. Career Points Scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style (unchanged)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6), facecolor='#f8f9fa')\n",
    "\n",
    "# Create scatter plot (only changed y-axis variable)\n",
    "scatter = sns.scatterplot(\n",
    "    x='salary',\n",
    "    y='career_PTS',  # Changed from career_FG3%\n",
    "    data=nba_salary_stats,\n",
    "    color='#2a9d8f',  # Original teal color\n",
    "    alpha=0.7,\n",
    "    s=80,\n",
    "    edgecolor='white',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "# Add regression line (only changed y-axis variable)\n",
    "sns.regplot(\n",
    "    x='salary',\n",
    "    y='career_PTS',  # Changed from career_FG3%\n",
    "    data=nba_salary_stats,\n",
    "    scatter=False,\n",
    "    color='#e76f51',  # Original coral color\n",
    "    line_kws={'linewidth': 2.5}\n",
    ")\n",
    "\n",
    "# Calculate and display correlation (changed variables)\n",
    "correlation = nba_salary_stats['salary'].corr(nba_salary_stats['career_PTS'])\n",
    "plt.text(0.05, 0.95, f'Correlation: {correlation:.2f}', \n",
    "         transform=plt.gca().transAxes,\n",
    "         fontsize=12,\n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='lightgray'))\n",
    "\n",
    "# Labels and title (only text changed)\n",
    "plt.title('Salary vs. Career Points',  # Changed title\n",
    "          fontsize=14, pad=15, fontweight='bold')\n",
    "plt.xlabel('Salary ($)', fontsize=12)  # Kept same\n",
    "plt.ylabel('Career Points', fontsize=12)  # Changed from 3-Point FG%\n",
    "\n",
    "# Adjust ticks (unchanged)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Clean up borders (unchanged)\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 Positions by Average Salary (Bar Chart)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Compute top 10 positions by average salary\n",
    "top_positions = (nba_salary_stats.groupby(\"position\")[\"salary\"]\n",
    "                 .mean()\n",
    "                 .sort_values(ascending=False)\n",
    "                 .head(10))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.barplot(x=top_positions.index, y=top_positions.values, palette=\"coolwarm\", ax=ax)\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Top 10 Positions by Average Salary\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Position\", fontsize=12)\n",
    "ax.set_ylabel(\"Average Salary ($)\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shooting hand preference frequency table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats[\"shoots\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking data shape before removing the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset has {nba_salary_stats.shape[0]} rows and {nba_salary_stats.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom function to remove the outliers:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def outlier_slayer(df):\n",
    "    data_clean = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    \n",
    "    # Initialize a mask to identify rows to keep\n",
    "    mask = pd.Series(True, index=data_clean.index)\n",
    "    \n",
    "    for column in data_clean.select_dtypes(include=[np.number]):\n",
    "        Q1 = data_clean[column].quantile(0.25)\n",
    "        Q3 = data_clean[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Update the mask to exclude rows with outliers in this column\n",
    "        mask &= (data_clean[column] >= lower_bound) & (data_clean[column] <= upper_bound)\n",
    "    \n",
    "    # Apply the mask to filter out rows with outliers in any column\n",
    "    data_clean = data_clean[mask]\n",
    "    \n",
    "    return data_clean\n",
    "\n",
    "# replace the dataframe with \n",
    "nba_salary_stats = outlier_slayer(nba_salary_stats)\n",
    "print(f\"Dataset without outliers has {nba_salary_stats.shape[0]} rows and {nba_salary_stats.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unneeded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.drop(columns=[\"league\", \"player_id\", \"season\", \"season_end\", \n",
    "                               \"index\", \"birthDate\", \"birthPlace\", \"career_TRB\",\n",
    "                               \"career_eFG%\", \"college\", \"draft_pick\", \"name\",\n",
    "                               \"draft_team\", \"draft_round\", \"draft_year\",\n",
    "                               \"highSchool\", \"birth_city\", \"nationality\",\n",
    "                               \"draft_age_clean\", \"draft_age_int\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = nba_salary_stats.corr(numeric_only=True)\n",
    "\n",
    "# Create mask for diagonal AND upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool)) | np.eye(corr_matrix.shape[0], dtype=bool)\n",
    "\n",
    "# Plot heatmap (shows only lower triangle, no diagonal)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,  # Hide diagonal + upper triangle\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "\n",
    "plt.grid(False)\n",
    "plt.title(\"Correlation Matrix\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select highly correlated features (above 50%) and remove multicollinearity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = nba_salary_stats.corr(numeric_only=True).abs()\n",
    "\n",
    "# Get upper triangle to avoid duplicates\n",
    "upper_triangle = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Find high correlations (≥50%)\n",
    "high_corr_pairs = (\n",
    "    corr_matrix\n",
    "    .where(upper_triangle)\n",
    "    .stack()\n",
    "    .loc[lambda x: (x >= 0.5) & (x < 1.0)]\n",
    "    .reset_index()\n",
    "    .rename(columns={'level_0': 'Feature_A', 'level_1': 'Feature_B', 0: 'Correlation'})\n",
    ")\n",
    "\n",
    "def select_feature(row):\n",
    "    \"\"\"Select feature with higher correlation to salary\"\"\"\n",
    "    corr_a = corr_matrix.loc[row[\"Feature_A\"], \"salary\"]\n",
    "    corr_b = corr_matrix.loc[row[\"Feature_B\"], \"salary\"]\n",
    "    return row[\"Feature_A\"] if corr_a > corr_b else row[\"Feature_B\"]\n",
    "\n",
    "# Apply selection\n",
    "high_corr_pairs[\"Selected_Feature\"] = high_corr_pairs.apply(select_feature, axis=1)\n",
    "\n",
    "# Get final selected features\n",
    "selected_features = high_corr_pairs[\"Selected_Feature\"].unique()\n",
    "\n",
    "print(\"Highly correlated feature pairs (≥50%):\")\n",
    "print(high_corr_pairs[['Feature_A', 'Feature_B', 'Correlation', 'Selected_Feature']])\n",
    "\n",
    "print(\"\\nSelected features (higher correlation with salary):\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and One Hot Encode\n",
    "- One Hot Encode for `team`, `position`, `shoots`\n",
    "- Normalize the remaining columns using `MinMaxScaler()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"season_start\", \"career_AST\", \"career_FG%\", \"career_FG3%\", \n",
    "                      \"career_FT%\", \"career_G\", \"career_PER\", \"career_PTS\", \"career_WS\", \n",
    "                      \"height\", \"weight\", \"draft_age\"]), # Normalize these columns\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"team\", \"position\", \"shoots\"]) # One hot encode these columns (pos, team)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), selected_features), # Normalize these columns\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"team\", \"position\", \"shoots\"]) # One hot encode these columns (pos, team)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nba_salary_stats.drop(\"salary\", axis=1) # Features\n",
    "y = nba_salary_stats[\"salary\"] # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train (80%) & test (20%) datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Training & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data \n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Normalized and One Hot Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Machine Learning Models with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    \"XGBoost Regressor\": xgb.XGBRegressor(n_estimators=50, random_state=42)\n",
    "}\n",
    "\n",
    "# Train models and evaluate performance\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_normal, y_train)\n",
    "    y_pred = model.predict(X_test_normal)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[model_name] = {'MAE': mae, 'RMSE': rmse, 'R^2': r2}\n",
    "\n",
    "# Print results\n",
    "print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    \"XGBoost Regressor\": xgb.XGBRegressor(n_estimators=50, random_state=42)\n",
    "}\n",
    "\n",
    "# Train models and evaluate performance\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_normal, y_train)\n",
    "    y_pred = model.predict(X_test_normal)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE calculation\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[model_name] = {'MAE': mae, 'RMSE': rmse, 'R²': r2}\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results).T  # Transpose for readability\n",
    "print(results_df)\n",
    "\n",
    "# Sort results for better visualization\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1]['MAE'])\n",
    "\n",
    "# Extract metrics for plotting\n",
    "model_names = [x[0] for x in sorted_results]\n",
    "mae_values = [x[1]['MAE'] for x in sorted_results]\n",
    "rmse_values = [x[1]['RMSE'] for x in sorted_results]\n",
    "r2_values = [x[1]['R²'] for x in sorted_results]\n",
    "\n",
    "# Plot the metrics\n",
    "x = np.arange(len(model_names))  # Label locations\n",
    "width = 0.35  # Bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot MAE and RMSE bars\n",
    "ax.bar(x - width/2, mae_values, width, label='MAE', color='#87CEEB', edgecolor='black', linewidth=1.2, alpha=0.9)\n",
    "ax.bar(x + width/2, rmse_values, width, label='RMSE', color='#1D2951', edgecolor='black', linewidth=1.2, alpha=0.9)\n",
    "\n",
    "# Add R² values as text on top of bars\n",
    "for i, (mae, rmse, r2) in enumerate(zip(mae_values, rmse_values, r2_values)):\n",
    "    ax.text(i, rmse + 0.01 * max(rmse_values), f'R²: {r2:.3f}', \n",
    "            ha='center', va='bottom', fontsize=10, color='black', fontweight='bold')\n",
    "\n",
    "# Labels, title, and formatting\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('MAE / RMSE')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even after transforming data, the well-known machine learning models do not give impressive results. The Random Forest Regressor has so far the best predictibility with R² = 0.76. <br>\n",
    "In the next part, we develop a neural network model which may improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure target variables are NumPy arrays\n",
    "y_train = np.array(y_train).astype(np.float32).reshape(-1, 1)  # Explicit conversion\n",
    "y_test = np.array(y_test).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# Ensure target variables are NumPy arrays\n",
    "y_train = np.array(y_train).astype(np.float32).reshape(-1, 1)  # Explicit conversion\n",
    "y_test = np.array(y_test).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(66)\n",
    "\n",
    "# Define the model\n",
    "nba_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nba_model.compile(loss=\"mae\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=[\"mae\"])\n",
    "\n",
    "# Train the model\n",
    "fit_data = nba_model.fit(X_train_normal, y_train, epochs=100, verbose=0)\n",
    "\n",
    "# Make predictions AFTER training\n",
    "y_pred = nba_model.predict(X_test_normal).flatten()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(root_mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaulate NBA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_model_loss, nba_model_mae = nba_model.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate prediction measures (MAE, RMSE, R²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot to see How Increasing Epochs Decreases Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size and style\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot training loss\n",
    "sns.lineplot(data=fit_data.history, linewidth=2.5, palette=\"tab10\")\n",
    "\n",
    "# Customize labels and title\n",
    "plt.xlabel(\"Epochs\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Loss\", fontsize=14, fontweight='bold')\n",
    "plt.title(\"Training Loss Over Epochs\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Improve tick visibility\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Add a legend for better understanding\n",
    "plt.legend(labels=fit_data.history.keys(), fontsize=12, loc=\"upper right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salary_stats.to_csv(\"nba_salary_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance using Random Forest Regressor on the NBA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data\n",
    "X = nba_salary_stats.drop(columns=['salary'])  # Features\n",
    "y = nba_salary_stats['salary']  # Target variable\n",
    "\n",
    "# Convert categorical features using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract feature importance scores\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).head(10)  # Top 10 features\n",
    "\n",
    "# Plot Feature Importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 10 Most Important Features for NBA Salary Prediction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
